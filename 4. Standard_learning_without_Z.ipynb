{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oh71mo6ebtdJ",
    "outputId": "31d922f5-4b1d-4c59-8d36-c1d48ae769bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EoNE-yvzwGIa",
    "outputId": "fe4a0e4c-25d9-4e65-bd21-e18f93510a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/690F\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/690F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5jhNHvAXb69D"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b2KSLRj0b_Ao"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"final_processed_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>...</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "      <th>comment_text_tokenized</th>\n",
       "      <th>prot_word_count</th>\n",
       "      <th>edited_comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This cool Its like want mother read Really gre...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>['this', 'cool', 'its', 'like', 'want', 'mothe...</td>\n",
       "      <td>0</td>\n",
       "      <td>this cool its like  mother read really great idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank This life lot anxietyinducing Keep let way</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>['thank', 'this', 'life', 'lot', 'anxietyinduc...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank this life lot anxietyindcing keep let way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This urgent design problem kudos taking Very i...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>['this', 'urgent', 'design', 'problem', 'kudos...</td>\n",
       "      <td>0</td>\n",
       "      <td>this rgent design problem kdos taking very imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is I able install site When releasing</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>['is', 'i', 'able', 'install', 'site', 'when',...</td>\n",
       "      <td>0</td>\n",
       "      <td>is i able install site when releasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha guys bunch losers</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>['haha', 'guys', 'bunch', 'losers']</td>\n",
       "      <td>0</td>\n",
       "      <td>haha gys bnch losers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id    target  \\\n",
       "0           0  59848  0.000000   \n",
       "1           1  59849  0.000000   \n",
       "2           2  59852  0.000000   \n",
       "3           3  59855  0.000000   \n",
       "4           4  59856  0.893617   \n",
       "\n",
       "                                        comment_text  severe_toxicity  \\\n",
       "0  This cool Its like want mother read Really gre...         0.000000   \n",
       "1   Thank This life lot anxietyinducing Keep let way         0.000000   \n",
       "2  This urgent design problem kudos taking Very i...         0.000000   \n",
       "3              Is I able install site When releasing         0.000000   \n",
       "4                             haha guys bunch losers         0.021277   \n",
       "\n",
       "   obscene  identity_attack   insult  threat  asian  ...  wow  sad  likes  \\\n",
       "0      0.0         0.000000  0.00000     0.0    NaN  ...    0    0      0   \n",
       "1      0.0         0.000000  0.00000     0.0    NaN  ...    0    0      0   \n",
       "2      0.0         0.000000  0.00000     0.0    NaN  ...    0    0      0   \n",
       "3      0.0         0.000000  0.00000     0.0    NaN  ...    0    0      0   \n",
       "4      0.0         0.021277  0.87234     0.0    0.0  ...    0    0      1   \n",
       "\n",
       "   disagree  sexual_explicit  identity_annotator_count  \\\n",
       "0         0              0.0                         0   \n",
       "1         0              0.0                         0   \n",
       "2         0              0.0                         0   \n",
       "3         0              0.0                         0   \n",
       "4         0              0.0                         4   \n",
       "\n",
       "   toxicity_annotator_count  \\\n",
       "0                         4   \n",
       "1                         4   \n",
       "2                         4   \n",
       "3                         4   \n",
       "4                        47   \n",
       "\n",
       "                              comment_text_tokenized  prot_word_count  \\\n",
       "0  ['this', 'cool', 'its', 'like', 'want', 'mothe...                0   \n",
       "1  ['thank', 'this', 'life', 'lot', 'anxietyinduc...                0   \n",
       "2  ['this', 'urgent', 'design', 'problem', 'kudos...                0   \n",
       "3  ['is', 'i', 'able', 'install', 'site', 'when',...                0   \n",
       "4                ['haha', 'guys', 'bunch', 'losers']                0   \n",
       "\n",
       "                                 edited_comment_text  \n",
       "0  this cool its like  mother read really great idea  \n",
       "1    thank this life lot anxietyindcing keep let way  \n",
       "2  this rgent design problem kdos taking very imp...  \n",
       "3              is i able install site when releasing  \n",
       "4                               haha gys bnch losers  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'target', 'comment_text', 'severe_toxicity',\n",
       "       'obscene', 'identity_attack', 'insult', 'threat', 'asian', 'atheist',\n",
       "       'bisexual', 'black', 'buddhist', 'christian', 'female', 'heterosexual',\n",
       "       'hindu', 'homosexual_gay_or_lesbian',\n",
       "       'intellectual_or_learning_disability', 'jewish', 'latino', 'male',\n",
       "       'muslim', 'other_disability', 'other_gender', 'other_race_or_ethnicity',\n",
       "       'other_religion', 'other_sexual_orientation', 'physical_disability',\n",
       "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
       "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
       "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
       "       'identity_annotator_count', 'toxicity_annotator_count',\n",
       "       'comment_text_tokenized', 'prot_word_count', 'edited_comment_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "ptoWTHjUcATg",
    "outputId": "36359b17-df9f-4c36-bd20-8c53d5ca4992"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>...</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>239579</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>This great story Man I wonder person yelled sh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>239607</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>Yet Muslims acts pilloried So okay smear entir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>239644</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Because people drive cars ones cause wear tear...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>239653</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>Mormons complicated relationship federal law</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>239744</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>I thing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target                                       comment_text  asian  \\\n",
       "11   239579  0.4400  This great story Man I wonder person yelled sh...    0.0   \n",
       "31   239607  0.9125  Yet Muslims acts pilloried So okay smear entir...    0.0   \n",
       "51   239644  0.0000  Because people drive cars ones cause wear tear...    0.0   \n",
       "58   239653  0.3000       Mormons complicated relationship federal law    0.0   \n",
       "111  239744  0.0000                                            I thing    0.0   \n",
       "\n",
       "     atheist  bisexual  black  buddhist  christian  female  ...  muslim  \\\n",
       "11       0.0       0.0    0.0       0.0        0.0     0.0  ...     0.0   \n",
       "31       0.0       0.0    0.0       0.0        1.0     0.0  ...     1.0   \n",
       "51       0.0       0.0    0.0       0.0        0.0     0.0  ...     0.0   \n",
       "58       0.0       0.0    0.0       0.0        0.2     0.0  ...     0.0   \n",
       "111      0.0       0.0    0.0       0.0        0.0     0.0  ...     0.0   \n",
       "\n",
       "     other_disability  other_gender  other_race_or_ethnicity  other_religion  \\\n",
       "11                0.0           0.0                      0.0             0.0   \n",
       "31                0.0           0.0                      0.0             0.0   \n",
       "51                0.0           0.0                      0.0             0.0   \n",
       "58                0.0           0.0                      0.0             0.2   \n",
       "111               0.0           0.0                      0.0             0.0   \n",
       "\n",
       "     other_sexual_orientation  physical_disability  \\\n",
       "11                        0.0                  0.0   \n",
       "31                        0.0                  0.0   \n",
       "51                        0.0                  0.0   \n",
       "58                        0.0                  0.0   \n",
       "111                       0.0                  0.0   \n",
       "\n",
       "     psychiatric_or_mental_illness  transgender  white  \n",
       "11                             0.0          0.0    0.0  \n",
       "31                             0.0          0.0    0.0  \n",
       "51                             0.0          0.0    0.0  \n",
       "58                             0.0          0.0    0.0  \n",
       "111                            0.0          0.0    0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df.dropna(inplace = True)\n",
    "to_show = ['id', 'target',\n",
    "       'comment_text', 'asian', 'atheist', 'bisexual', 'black', 'buddhist',\n",
    "       'christian', 'female', 'heterosexual', 'hindu',\n",
    "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
    "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
    "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
    "       'other_sexual_orientation', 'physical_disability',\n",
    "       'psychiatric_or_mental_illness', 'transgender', 'white']\n",
    "train_df.head().loc[:, to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4zlSOOa4EJHu"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['target'] >= 0.20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O65GzN5VcCMM",
    "outputId": "56bcac3b-17e5-4414-dacd-9b8a5b427f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non toxic comments: 41566\n",
      "Number of toxic comments: 25142\n"
     ]
    }
   ],
   "source": [
    "# the number of non toxic comments was more than 10 times the number of toxic comments, we have subsampled it to the following distribution\n",
    "print(\"Number of non toxic comments: \"+str(len(train_df[train_df[\"target\"] < 0.5])))\n",
    "print(\"Number of toxic comments: \"+str(len(train_df[train_df[\"target\"] >= 0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQkbVZxDcEkw",
    "outputId": "06495068-7a74-4196-f466-ecc3b8acb891"
   },
   "outputs": [],
   "source": [
    "train_df[\"prot_word_count\"][train_df[\"prot_word_count\"] > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZHBj7yIcGg4",
    "outputId": "abf253fb-456f-48c6-c1c2-994fd1ae57b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments with bias inducing words not present: 28700\n",
      "Number of comments with bias inducing words present: 38008\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of comments with bias inducing words not present: \" + str(len(train_df[train_df[\"prot_word_count\"] == 0])))\n",
    "print(\"Number of comments with bias inducing words present: \" + str(len(train_df[train_df[\"prot_word_count\"] == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8Xm7D4x0cIVs"
   },
   "outputs": [],
   "source": [
    "X = train_df[[\"comment_text\", \"prot_word_count\", \"edited_comment_text\"]]\n",
    "y = np.array(train_df['target'].apply(lambda x: x > .5).astype('int'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_attr = ['transgendered', 'sex', 'bigotry', 'racist', 'muslim', 'racism', 'priest', 'black', 'sexual', 'latino', 'man', 'islam', 'gay', 'men', 'straight', 'transgender', 'homosexual', 'jewish', 'catholic', 'heterosexual', 'women', 'church', 'religious', 'military', 'asian', 'hindu', 'buddhist', 'religion', 'atheist', 'white', 'chinese', 'male', 'christian', 'race', 'bisexual', 'jew', 'woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DFjHFGF3smKJ"
   },
   "outputs": [],
   "source": [
    "# Standard Learning without Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "Xvec = vectorizer.fit_transform(X['edited_comment_text'])\n",
    "X_vect = pd.DataFrame(Xvec.todense(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colstodrop 63444\n",
      "orig_cols 76943\n",
      "new_cols 13499\n"
     ]
    }
   ],
   "source": [
    "word_counts = {}\n",
    "cols_to_drop = []\n",
    "for i in list(X_vect.columns):\n",
    "    X_vect[i][X_vect[i] > 0] = 1\n",
    "    col_total = X_vect[i].sum()\n",
    "    word_counts[i] = col_total\n",
    "    if col_total < 11:\n",
    "        cols_to_drop.append(i)\n",
    "\n",
    "print(\"colstodrop\",len(cols_to_drop))\n",
    "print(\"orig_cols\",len(X_vect.columns))\n",
    "X_vect.drop(cols_to_drop, axis=1, inplace = True)\n",
    "print(\"new_cols\",len(X_vect.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vect.to_csv(\"edited_comment_X_vect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=.4, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Fitting a simple Logistic Regression on tf-idf\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7793434267725978\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \"+str(lr.score(X_test, y_test)))\n",
    "y_preds = lr.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_ml_without_z = pd.DataFrame({\"Feature\" : X_vect.columns.tolist(),\"Coefficients\" : lr.coef_[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>asian</td>\n",
       "      <td>-0.315275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>atheist</td>\n",
       "      <td>0.172630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>catholic</td>\n",
       "      <td>-0.491175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>chinese</td>\n",
       "      <td>0.240093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>christian</td>\n",
       "      <td>-0.057505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>islam</td>\n",
       "      <td>0.273566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>jew</td>\n",
       "      <td>0.486719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6608</th>\n",
       "      <td>jewish</td>\n",
       "      <td>-0.133100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.410707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>men</td>\n",
       "      <td>0.204320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>military</td>\n",
       "      <td>-0.167282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587</th>\n",
       "      <td>priest</td>\n",
       "      <td>-0.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12057</th>\n",
       "      <td>straight</td>\n",
       "      <td>-0.065936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Coefficients\n",
       "744        asian     -0.315275\n",
       "827      atheist      0.172630\n",
       "1788    catholic     -0.491175\n",
       "1983     chinese      0.240093\n",
       "2011   christian     -0.057505\n",
       "6493       islam      0.273566\n",
       "6605         jew      0.486719\n",
       "6608      jewish     -0.133100\n",
       "6892      latino      0.410707\n",
       "7520         men      0.204320\n",
       "7592    military     -0.167282\n",
       "9587      priest     -0.220700\n",
       "12057   straight     -0.065936"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_ml_without_z[coeffs_ml_without_z['Feature'].isin(prot_attr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = coeffs_ml_without_z[coeffs_ml_without_z['Feature'].isin(prot_attr)]\n",
    "res.to_csv(\"coeffs_ml_without_z.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'religion': 0.004348001324842509,\n",
       " 'race': 0.11184151860766274,\n",
       " 'gender': 0.20431975186541906,\n",
       " 'sexual_identity': -0.06593569425689184,\n",
       " 'misc': -0.16728225904961355}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = {\n",
    "'religion' : ['religion', 'religious', 'atheist', 'buddhist', 'christian', 'hindu', 'jewish', 'muslim', 'catholic', 'church', 'islam', 'jew', 'priest'],\n",
    "'race' : ['asian', 'black', 'latino', 'white', 'chinese', 'race', 'racism'],\n",
    "'gender' : ['female', 'male', 'transgender', 'man', 'men', 'trangendered', 'woman', 'women'],\n",
    "'sexual_identity' : ['bisexual', 'heterosexual', 'gay', 'homosexual', 'sex', 'sexual', 'straight' ],\n",
    "'misc' : ['bigotry', 'military']\n",
    "}\n",
    "\n",
    "avg_coeffs = {}\n",
    "\n",
    "for group in groups:\n",
    "    avg_coeff = np.mean(np.array(coeffs_ml_without_z[coeffs_ml_without_z['Feature'].isin(groups[group])]['Coefficients']))\n",
    "    avg_coeffs[group] = avg_coeff\n",
    "\n",
    "avg_coeffs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
